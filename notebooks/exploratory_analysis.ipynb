{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19143fd8e5e59bc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:54:25.278086Z",
     "start_time": "2025-12-04T16:54:25.212552Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from nbs_uncertainty.readers.bathymetry import load_file\n",
    "from nbs_uncertainty.processors.bathy_processors import BathyProcessor\n",
    "from nbs_uncertainty.estimators import uncertaintyEstimators\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153c982131fb5406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T17:01:12.490018Z",
     "start_time": "2025-12-04T17:01:12.294723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: RasterBathymetry\n",
      " Filename: BlueTopo.tiff\n",
      " Location: ..\\data\\raster\n",
      " Resolution: 4.0\n",
      " No Data Value: 1000000.0\n",
      " Min\\Max value: [(np.float32(-106.318), np.float32(-35.669))]\n",
      " Data Shape: (2035, 1493)\n"
     ]
    }
   ],
   "source": [
    "# define bathymetry filename\n",
    "# directory location defined in config.ini file under config folder\n",
    "filename = \"BlueTopo.tiff\"\n",
    "\n",
    "# Read filename and load bathy data\n",
    "bathy_data = load_file(filename)\n",
    "print(bathy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447c3c47d2f44d70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T17:01:13.610967Z",
     "start_time": "2025-12-04T17:01:13.601135Z"
    }
   },
   "outputs": [],
   "source": [
    "# define processing parameters\n",
    "linespacing = 32\n",
    "max_multiple = 4\n",
    "current_multiple = 1\n",
    "settings = {'linespacing': linespacing,\n",
    "            'max_multiple': max_multiple,\n",
    "            'current_multiple': current_multiple}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648fbc277bf867af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T17:04:04.590364Z",
     "start_time": "2025-12-04T17:04:04.494197Z"
    }
   },
   "outputs": [],
   "source": [
    "residual = BathyProcessor.compute_residual(bathy_data, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd0bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = BathyProcessor.estimate_uncertainty('psd', bathy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7bd68f71ac022",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy import signal\n",
    "# import matplotlib.pyplot as plt\n",
    "# from uncertainty_estimation import data_utils, matrix_utils\n",
    "# from scipy.stats import genextreme, norm\n",
    "# # Collection of utility functions for FFT Computations for Uncertainty\n",
    "\n",
    "\n",
    "# def compute_residual(data_strip: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Compute the residual error from estimating the data using\n",
    "#     linear interpolation\n",
    "\n",
    "#     This function computes the estimate for the data strip\n",
    "#     using the edge values and returns the residual error\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "\n",
    "#     data_strip : np.array\n",
    "#                  Bathymetric data strips re-aranged to a single strip\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     residual : np.array\n",
    "#                Difference of the interpolation from the input data strip\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     interpolated_strip = np.linspace(start=data_strip[:, 0],\n",
    "#                                      stop=data_strip[:, -1],\n",
    "#                                      num=data_strip.shape[1])\n",
    "\n",
    "#     interpolated_strip = interpolated_strip.T\n",
    "#     residual = data_strip - interpolated_strip\n",
    "\n",
    "#     return residual, interpolated_strip\n",
    "\n",
    "\n",
    "\n",
    "# # # Elias modified 1\n",
    "# # def compute_energy(data: np.ndarray,\n",
    "# #                    resolution: int,\n",
    "# #                    method: str,\n",
    "# #                    window_values: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "# #     \"\"\"\n",
    "# #     Compute FFT energy using 'method' process\n",
    "# #\n",
    "# #     Parameters\n",
    "# #     ----------\n",
    "# #     data : np.array\n",
    "# #            Input data\n",
    "# #     resolution : int\n",
    "# #                  Spatial resoluton of the array\n",
    "# #     method : str\n",
    "# #              FFT Method used to estimate signal energy\n",
    "# #\n",
    "# #     Returns\n",
    "# #     -------\n",
    "# #     np.array\n",
    "# #             Spectral energy in the signal\n",
    "# #     \"\"\"\n",
    "# #\n",
    "# #     rfft_values = np.abs(np.fft.rfft(data, axis=1))\n",
    "# #     _, num_cols = rfft_values.shape\n",
    "# #     r_frequencies = np.fft.rfftfreq(data.shape[1], d=resolution)\n",
    "# #\n",
    "# #     if method == \"amplitude\": #ASD in Scipy doc\n",
    "# #         scale_factor = np.sqrt(np.sum(window_values** 2)) / np.sqrt(resolution)\n",
    "# #         if num_cols % 2 == 0:\n",
    "# #             rfft_values[:, 1:-1] = rfft_values[:, 1:-1] * 2\n",
    "# #             rfft_values = rfft_values[:, :-1]\n",
    "# #             r_frequencies = r_frequencies[:-1]\n",
    "# #         else:\n",
    "# #             rfft_values[:, 1:] = rfft_values[:, 1:] * 2\n",
    "# #\n",
    "# #     elif method == \"psd\":\n",
    "# #         scale_factor = np.sqrt(np.sum(window_values** 2)) / resolution\n",
    "# #         rfft_values = rfft_values**2\n",
    "# #         if num_cols % 2 == 0:\n",
    "# #             rfft_values[:, 1:-1] = rfft_values[:, 1:-1] * 2\n",
    "# #         else:\n",
    "# #             rfft_values[:, 1:] = rfft_values[:, 1:] * 2\n",
    "# #         rfft_values = rfft_values[:, :-1]\n",
    "# #         r_frequencies = r_frequencies[:-1]\n",
    "# #\n",
    "# #     elif method == \"spectrum\": #amplitude spectrum\n",
    "# #         scale_factor = np.abs(np.sum(window_values))\n",
    "# #         # rfft_values = rfft_values**2\n",
    "# #         if num_cols % 2 == 0:\n",
    "# #             rfft_values[:, 1:-1] = rfft_values[:, 1:-1] * 2\n",
    "# #         else:\n",
    "# #             rfft_values[:, 1:] = rfft_values[:, 1:] * 2\n",
    "# #         rfft_values = rfft_values[:, :-1]\n",
    "# #         r_frequencies = r_frequencies[:-1]\n",
    "# #\n",
    "# #     else:\n",
    "# #         raise ValueError(\n",
    "# #             f\"\"\"Unknown FFT Method: {method}\n",
    "# #                 FFT options: {'amplitude', 'psd', 'spectrum'}\n",
    "# #                 \"\"\")\n",
    "# #\n",
    "# #     energy = rfft_values / scale_factor\n",
    "# #\n",
    "# #     return energy, r_frequencies\n",
    "\n",
    "# # # Elias modified 2\n",
    "# # def compute_energy(data: np.ndarray,\n",
    "# #                    resolution: int,\n",
    "# #                    method: str,\n",
    "# #                    window_values: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "# #     \"\"\"\n",
    "# #     Compute FFT energy using 'method' process\n",
    "# #\n",
    "# #     Parameters\n",
    "# #     ----------\n",
    "# #     data : np.array\n",
    "# #            Input data\n",
    "# #     resolution : int\n",
    "# #                  Spatial resoluton of the array\n",
    "# #     method : str\n",
    "# #              FFT Method used to estimate signal energy\n",
    "# #\n",
    "# #     Returns\n",
    "# #     -------\n",
    "# #     np.array\n",
    "# #             Spectral energy in the signal\n",
    "# #     \"\"\"\n",
    "# #\n",
    "# #     rfft_values = np.abs(np.fft.rfft(data, axis=1))\n",
    "# #     _, num_cols = rfft_values.shape\n",
    "# #     r_frequencies = np.fft.rfftfreq(data.shape[1], d=resolution)\n",
    "# #\n",
    "# #     if method == \"amplitude\": #ASD in Scipy doc\n",
    "# #         cden = np.sqrt(np.sum(window_values** 2))\n",
    "# #         if num_cols % 2 == 0:\n",
    "# #             rfft_values[:, 1:-1] = rfft_values[:, 1:-1] * 2\n",
    "# #             rfft_values = rfft_values[:, :-1]\n",
    "# #             r_frequencies = r_frequencies[:-1]\n",
    "# #         else:\n",
    "# #             rfft_values[:, 1:] = rfft_values[:, 1:] * 2\n",
    "# #\n",
    "# #         energy = np.sqrt(resolution) * rfft_values / cden\n",
    "# #\n",
    "# #     elif method == \"psd\":\n",
    "# #         cden = np.sqrt(np.sum(window_values** 2))\n",
    "# #         if num_cols % 2 == 0:\n",
    "# #             rfft_values[:, 1:-1] = rfft_values[:, 1:-1] * 2\n",
    "# #         else:\n",
    "# #             rfft_values[:, 1:] = rfft_values[:, 1:] * 2\n",
    "# #         rfft_values = rfft_values[:, :-1]\n",
    "# #         r_frequencies = r_frequencies[:-1]\n",
    "# #\n",
    "# #         energy =  resolution * (np.abs(rfft_values / cden)**2)\n",
    "# #\n",
    "# #     elif method == \"spectrum\": #amplitude spectrum\n",
    "# #         camp = np.abs(np.sum(window_values))\n",
    "# #         if num_cols % 2 == 0:\n",
    "# #             rfft_values[:, 1:-1] = rfft_values[:, 1:-1] * 2\n",
    "# #         else:\n",
    "# #             rfft_values[:, 1:] = rfft_values[:, 1:] * 2\n",
    "# #         rfft_values = rfft_values[:, :-1]\n",
    "# #         r_frequencies = r_frequencies[:-1]\n",
    "# #\n",
    "# #         energy = rfft_values / camp\n",
    "# #\n",
    "# #     else:\n",
    "# #         raise ValueError(\n",
    "# #             f\"\"\"Unknown FFT Method: {method}\n",
    "# #                 FFT options: {'amplitude', 'psd', 'spectrum'}\n",
    "# #                 \"\"\")\n",
    "# #\n",
    "# #     # energy = rfft_values / scale_factor\n",
    "# #\n",
    "# #     return energy, r_frequencies\n",
    "\n",
    "# # Elias modified 3\n",
    "# def compute_energy(data: np.ndarray,\n",
    "#                    resolution: int,\n",
    "#                    method: str,\n",
    "#                    window_values: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Compute FFT energy using 'method' process\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data : np.array\n",
    "#            Input data\n",
    "#     resolution : int\n",
    "#                  Spatial resoluton of the array\n",
    "#     method : str\n",
    "#              FFT Method used to estimate signal energy\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     np.array\n",
    "#             Spectral energy in the signal\n",
    "#     \"\"\"\n",
    "\n",
    "#     rfft_values = np.abs(np.fft.rfft(data, axis=1))\n",
    "#     _, num_cols = rfft_values.shape\n",
    "#     r_frequencies = np.fft.rfftfreq(data.shape[1], d=resolution)\n",
    "\n",
    "#     if method == \"amplitude\": #ASD in Scipy doc\n",
    "\n",
    "#         cden = np.sqrt(np.sum(window_values** 2))\n",
    "#         energy = np.sqrt(resolution) * rfft_values / cden\n",
    "\n",
    "#         if num_cols % 2 == 0:\n",
    "#             energy[:, 1:-1] = energy[:, 1:-1] * 2\n",
    "#         else:\n",
    "#             energy[:, 1:] = energy[:, 1:] * 2\n",
    "\n",
    "#         energy = energy[:, :-1]\n",
    "#         r_frequencies = r_frequencies[:-1]\n",
    "\n",
    "#     elif method == \"psd\" or \"psd_n\" or \"psd_df\" or \"psd_lf\":\n",
    "#         cden = np.sqrt(np.sum(window_values** 2))\n",
    "#         energy =  resolution * (np.abs(rfft_values / cden)**2)\n",
    "\n",
    "#         if num_cols % 2 == 0:  # even length → Nyquist bin exists\n",
    "#             energy[:, 1:-1] *= 2\n",
    "#         else:  # odd length → no Nyquist bin\n",
    "#             energy[:, 1:] *= 2\n",
    "\n",
    "#         energy = energy[:, :-1]\n",
    "#         r_frequencies = r_frequencies[:-1]\n",
    "\n",
    "#     elif method == \"spectrum\": #used for psd too\n",
    "#         # camp = np.abs(np.sum(window_values))\n",
    "#         #\n",
    "#         # energy = rfft_values / camp\n",
    "#         #\n",
    "#         # if num_cols % 2 == 0:  # even length → Nyquist bin exists\n",
    "#         #     energy[:, 1:-1] *= 2\n",
    "#         # else:  # odd length → no Nyquist bin\n",
    "#         #     energy[:, 1:] *= 2\n",
    "\n",
    "#         cden = np.sqrt(np.sum(window_values** 2))\n",
    "#         energy =  resolution * (np.abs(rfft_values / cden)**2)\n",
    "\n",
    "#         if num_cols % 2 == 0:  # even length → Nyquist bin exists\n",
    "#             energy[:, 1:-1] *= 2\n",
    "#         else:  # odd length → no Nyquist bin\n",
    "#             energy[:, 1:] *= 2\n",
    "\n",
    "#         energy = energy[:, :-1]\n",
    "#         r_frequencies = r_frequencies[:-1]\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\n",
    "#             f\"\"\"Unknown FFT Method: {method}\n",
    "#                 FFT options: {'amplitude', 'psd', 'spectrum'}\n",
    "#                 \"\"\")\n",
    "\n",
    "#     # energy = rfft_values / scale_factor\n",
    "\n",
    "#     return energy, r_frequencies\n",
    "\n",
    "# def create_spatial_signal(resolution: int, max_cell_number: int):\n",
    "#     \"\"\"\n",
    "#     Create the distance and frequency dependent scaling factors.\n",
    "#     \"\"\"\n",
    "#     frequencies = np.fft.rfftfreq(max_cell_number, resolution)\n",
    "#     if len(frequencies) % 2 == 0:\n",
    "#         frequencies = frequencies[:-1]\n",
    "#     distances = np.arange(max_cell_number) * resolution\n",
    "#     distances_2d, freq_2d = np.meshgrid(distances, frequencies)\n",
    "#     spatial_scale = distances_2d * freq_2d\n",
    "#     spatial_scale = np.where(spatial_scale < 0.25, spatial_scale, 0.25)\n",
    "#     spatial_signal = np.sin(spatial_scale * 2 * np.pi)\n",
    "\n",
    "#     return spatial_signal\n",
    "\n",
    "# # def compute_fft_uncertainty(\n",
    "# #     data: np.ndarray,\n",
    "# #     multiple: int,\n",
    "# #     resolution: int,\n",
    "# #     windowing: str = 'hann',\n",
    "# #     method: str = \"amplitude\",\n",
    "# #     selection: str = \"half\",\n",
    "# # ) -> np.ndarray:\n",
    "# #     \"\"\"\n",
    "# #     Estimate the uncertainty using FFT\n",
    "# #\n",
    "# #     Parameters\n",
    "# #     ----------\n",
    "# #     data : np.array\n",
    "# #            Input data for FFT estimation\n",
    "# #     multiple : int\n",
    "# #                Window length as multiple of the linespacing\n",
    "# #     resolution : int\n",
    "# #                  Input data resolution for frequency calculation\n",
    "# #     windowing : str\n",
    "# #                 Type of window to taper input\n",
    "# #                 options: scipy.signal.windows type\n",
    "# #     method : str\n",
    "# #              Type of FFT to estimate energy, defaults to 'amplitude'\n",
    "# #              options: ['amplitude', 'psd', 'spectrum']\n",
    "# #\n",
    "# #\n",
    "# #     Returns\n",
    "# #     -------\n",
    "# #     output : np.ndarray\n",
    "# #         Uncertainty estimate from the FFT method\n",
    "# #         To be compared with the residual error\n",
    "# #\n",
    "# #     \"\"\"\n",
    "# #\n",
    "# #     if data.ndim < 2:\n",
    "# #         data = data.reshape(1, -1)\n",
    "# #\n",
    "# #     # create window\n",
    "# #     segment_window = signal.windows.get_window(\n",
    "# #         window=windowing, Nx=data.shape[1], fftbins=False)\n",
    "# #\n",
    "# #     # preprocess_signal, could be modified later\n",
    "# #     # data_mean = np.mean(data, axis=1)\n",
    "# #     preprocessed_signal = data * segment_window\n",
    "# #\n",
    "# #     energy, energy_freqs = compute_energy(preprocessed_signal,\n",
    "# #                                             resolution,\n",
    "# #                                             method,\n",
    "# #                                             segment_window)\n",
    "# #\n",
    "# #     # compute contribution per frequency\n",
    "# #     spatial_signal = create_spatial_signal(resolution, data.shape[1])\n",
    "# #     variance = energy @ spatial_signal\n",
    "# #\n",
    "# #     # normalize energy (convert m^2 to meters)\n",
    "# #     if method == \"amplitude\":\n",
    "# #         window_uncertainty = variance\n",
    "# #     else:\n",
    "# #         variance = variance / len(energy_freqs)\n",
    "# #         window_uncertainty = np.sqrt(variance)\n",
    "# #\n",
    "# #     # Remove edges when computing the original linespacing\n",
    "# #     linespacing_width = int((data.shape[1]-2) / multiple)\n",
    "# #     # Include edges again for the output strip\n",
    "# #     output = np.zeros(shape=(data.shape[0], linespacing_width + 2))\n",
    "# #     num_cols = output.shape[1]\n",
    "# #\n",
    "# #     if selection == \"half\":\n",
    "# #         selected_data = window_uncertainty[:, :int(num_cols/2)]\n",
    "# #         output[:, :int(num_cols/2)] = selected_data\n",
    "# #         output[:, int(num_cols/2):] = np.fliplr(selected_data)\n",
    "# #     else:\n",
    "# #         # pick energy from frequencies only present in original data\n",
    "# #         freqs_window = np.fft.rfftfreq(int(data.shape[1] / multiple),\n",
    "# #                                        resolution)\n",
    "# #         freq_idxs = np.where(np.isin(freqs_window, energy_freqs))[0]\n",
    "# #         selected_data = window_uncertainty[:, freq_idxs]\n",
    "# #         output[:, :int(num_cols/2)] = selected_data\n",
    "# #         output[:, int(num_cols/2):] = np.fliplr(selected_data)\n",
    "# #\n",
    "# #     return output\n",
    "\n",
    "# # Elias modified\n",
    "# def compute_fft_uncertainty(\n",
    "#     data: np.ndarray,\n",
    "#     multiple: int,\n",
    "#     resolution: int,\n",
    "#     windowing: str = 'hann',\n",
    "#     method: str = \"amplitude\",\n",
    "#     selection: str = \"half\",\n",
    "# ) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Estimate the uncertainty using FFT\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data : np.array\n",
    "#            Input data for FFT estimation\n",
    "#     multiple : int\n",
    "#                Window length as multiple of the linespacing\n",
    "#     resolution : int\n",
    "#                  Input data resolution for frequency calculation\n",
    "#     windowing : str\n",
    "#                 Type of window to taper input\n",
    "#                 options: scipy.signal.windows type\n",
    "#     method : str\n",
    "#              Type of FFT to estimate energy, defaults to 'amplitude'\n",
    "#              options: ['amplitude', 'psd', 'spectrum']\n",
    "\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     output : np.ndarray\n",
    "#         Uncertainty estimate from the FFT method\n",
    "#         To be compared with the residual error\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     if data.ndim < 2:\n",
    "#         data = data.reshape(1, -1)\n",
    "\n",
    "\n",
    "\n",
    "#     # create window\n",
    "#     segment_window = signal.windows.get_window(\n",
    "#         window=windowing, Nx=data.shape[1], fftbins=True)\n",
    "\n",
    "#     # preprocess_signal, could be modified later\n",
    "#     # data_mean = np.mean(data, axis=1)\n",
    "#     preprocessed_signal = data * segment_window\n",
    "\n",
    "#     energy, energy_freqs = compute_energy(preprocessed_signal,\n",
    "#                                             resolution,\n",
    "#                                             method,\n",
    "#                                             segment_window)\n",
    "\n",
    "#     df = 1.0 / (data.shape[1] * resolution)\n",
    "\n",
    "#     # compute contribution per frequency\n",
    "#     spatial_signal = create_spatial_signal(resolution, data.shape[1])\n",
    "\n",
    "#     if method == \"amplitude\":\n",
    "#         variance = (((energy**2)/data.shape[1])) @ spatial_signal\n",
    "#     elif method == \"psd\":\n",
    "#         variance = ((energy/data.shape[1])) @ spatial_signal\n",
    "#     elif method == \"psd_n\":\n",
    "#         variance = ((energy/data.shape[1])) @ spatial_signal\n",
    "#     elif method == \"psd_df\":\n",
    "#         variance = ((energy*df)) @ spatial_signal\n",
    "#     elif method == \"psd_lf\":\n",
    "#         variance = ((energy/len(energy_freqs))) @ spatial_signal\n",
    "#     elif method == \"spectrum\":\n",
    "#         variance = ((energy/len(energy_freqs))) @ spatial_signal\n",
    "\n",
    "#     # if method == \"amplitude\":\n",
    "#     #     variance = (((energy**2)*df)) @ spatial_signal\n",
    "#     # elif method == \"psd\":\n",
    "#     #     variance = ((energy*df)) @ spatial_signal\n",
    "#     # elif method == \"spectrum\":\n",
    "#     #     variance = ((energy*df)) @ spatial_signal\n",
    "\n",
    "#     window_uncertainty = np.sqrt(variance)\n",
    "\n",
    "\n",
    "#     # Remove edges when computing the original linespacing\n",
    "#     linespacing_width = int((data.shape[1]-2) / multiple)\n",
    "#     # Include edges again for the output strip\n",
    "#     output = np.zeros(shape=(data.shape[0], linespacing_width + 2))\n",
    "#     num_cols = output.shape[1]\n",
    "\n",
    "#     if selection == \"half\":\n",
    "#         selected_data = window_uncertainty[:, :int(num_cols/2)]\n",
    "#         output[:, :int(num_cols/2)] = selected_data\n",
    "#         output[:, int(num_cols/2):] = np.fliplr(selected_data)\n",
    "#     else:\n",
    "#         # pick energy from frequencies only present in original data\n",
    "#         freqs_window = np.fft.rfftfreq(int(data.shape[1] / multiple),\n",
    "#                                        resolution)\n",
    "#         freq_idxs = np.where(np.isin(freqs_window, energy_freqs))[0]\n",
    "#         selected_data = window_uncertainty[:, freq_idxs]\n",
    "#         output[:, :int(num_cols/2)] = selected_data\n",
    "#         output[:, int(num_cols/2):] = np.fliplr(selected_data)\n",
    "\n",
    "#     return output\n",
    "\n",
    "# # def get_difference_uncertainties_max(data:np.ndarray,\n",
    "# #                                       min_window:int = 2,\n",
    "# #                                       multiple:int = 1, method='diff'):\n",
    "# #     \"\"\"\n",
    "# #     Calculate the variance of the provided data array in parts.\n",
    "# #     \"\"\"\n",
    "# #\n",
    "# #     num_lines, num_samples = data.shape\n",
    "# #     interpolation_cell_distance = num_samples\n",
    "# #     interpolation_cell_distance = ((interpolation_cell_distance-2)//multiple)+2\n",
    "# #     # interpolation_cell_distance = num_samples\n",
    "# #     difference_max = np.full((num_lines, interpolation_cell_distance), 0.0)\n",
    "# #     difference_mean = np.full((num_lines, interpolation_cell_distance), 0.0)\n",
    "# #     std_mean = np.full((num_lines, interpolation_cell_distance), 0.0)\n",
    "# #     for win_len in range(min_window, interpolation_cell_distance//2+1):\n",
    "# #         num_convolutions = num_samples - win_len + 1\n",
    "# #         differences = np.full((num_lines, num_convolutions), 0.0)\n",
    "# #         stds = np.full((num_lines, num_convolutions), 0.0)\n",
    "# #         for step in range(num_convolutions):\n",
    "# #             mins = np.min(data[:,step:step+win_len], axis = -1)\n",
    "# #             maxs = np.max(data[:,step:step+win_len], axis = -1)\n",
    "# #             differences[:,step] = maxs - mins\n",
    "# #             stds[:,step] = np.std(data[:, step:step + win_len], axis=-1)\n",
    "# #         difference_max[:, win_len-1] = np.max(differences, axis=-1)\n",
    "# #         difference_mean[:, win_len-1] = np.mean(differences, axis =-1)\n",
    "# #         std_mean[:, win_len-1] = np.mean(stds, axis =-1) # std of the values in the window instead of taking the max min diff, in line with 2D case\n",
    "# #     # print(f\"final convolutions for window length {win_len} is {num_convolutions}\")\n",
    "# #     difference_max[:,-win_len:] = np.fliplr(difference_max[:, :win_len])\n",
    "# #     difference_mean[:,-win_len:] = np.fliplr(difference_mean[:, :win_len])\n",
    "# #     std_mean[:,-win_len:] = np.fliplr(std_mean[:,:win_len])\n",
    "# #     return difference_max, difference_mean, std_mean\n",
    "\n",
    "# # let's add GEV and Gaussian fit\n",
    "# import numpy as np\n",
    "# from numpy.lib.stride_tricks import sliding_window_view\n",
    "# from scipy.stats import genextreme, norm\n",
    "\n",
    "# def get_difference_uncertainties_max(\n",
    "#     data: np.ndarray,\n",
    "#     min_window: int = 2,\n",
    "#     multiple: int = 1,\n",
    "#     method: str = \"diff\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Efficiently compute uncertainty estimates (diff, std, GEV, Gaussian)\n",
    "#     using sliding window views instead of explicit loops.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data : np.ndarray\n",
    "#         2D array of shape (num_lines, num_samples).\n",
    "#     min_window : int\n",
    "#         Minimum window length to start sliding over.\n",
    "#     multiple : int\n",
    "#         Multiplier controlling the spacing of the windows.\n",
    "#     method : str\n",
    "#         One of ['diff', 'std', 'gev', 'gaussian'].\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     Tuple of np.ndarray\n",
    "#         Depending on `method`, returns corresponding uncertainty statistics.\n",
    "#     \"\"\"\n",
    "\n",
    "#     num_lines, num_samples = data.shape\n",
    "#     interpolation_cell_distance = ((num_samples - 2) // multiple) + 2\n",
    "\n",
    "#     # Preallocate arrays\n",
    "#     shape = (num_lines, interpolation_cell_distance)\n",
    "#     difference_mean = np.zeros(shape)\n",
    "#     difference_max = np.zeros(shape)\n",
    "#     diff_envelope1 = np.zeros(shape)\n",
    "#     diff_envelope2 = np.zeros(shape)\n",
    "#     diff_envelope3 = np.zeros(shape)\n",
    "#     std_mean = np.zeros(shape)\n",
    "#     std_max = np.zeros(shape)\n",
    "#     std_envelope1 = np.zeros(shape)\n",
    "#     std_envelope2 = np.zeros(shape)\n",
    "#     std_envelope3 = np.zeros(shape)\n",
    "#     gev_mean = np.zeros(shape)\n",
    "#     gev_p95_stats = np.zeros(shape)\n",
    "#     gev_p99_stats = np.zeros(shape)\n",
    "#     gaussian_mean = np.zeros(shape)\n",
    "#     gaussian_p95_stats = np.zeros(shape)\n",
    "#     gaussian_p99_stats = np.zeros(shape)\n",
    "\n",
    "#     # --- Main computation loop ---\n",
    "#     for win_len in range(min_window, interpolation_cell_distance // 2 + 1):\n",
    "#         windows = sliding_window_view(data, window_shape=win_len, axis=-1)\n",
    "#         # windows shape: (num_lines, num_convolutions, win_len)\n",
    "#         mins = np.min(windows, axis=-1)\n",
    "#         maxs = np.max(windows, axis=-1)\n",
    "#         differences = maxs - mins\n",
    "#         stds = np.std(windows, axis=-1)\n",
    "\n",
    "#         # --- STD stats ---\n",
    "#         if method == 'std':\n",
    "#             std_mean[:, win_len-1] = np.mean(stds, axis=-1)\n",
    "#             std_max[:, win_len-1] = np.max(stds, axis=-1)\n",
    "#             std_std = np.std(stds, axis=-1)\n",
    "#             std_envelope1[:, win_len-1] = std_mean[:, win_len-1] + std_std\n",
    "#             std_envelope2[:, win_len-1] = std_mean[:, win_len-1] + 2 * std_std\n",
    "#             std_envelope3[:, win_len-1] = std_mean[:, win_len-1] + 3 * std_std\n",
    "\n",
    "#         # --- DIFF stats ---\n",
    "#         elif method == 'diff':\n",
    "#             diff_mean = np.mean(differences, axis=-1)\n",
    "#             diff_std = np.std(differences, axis=-1)\n",
    "#             diff_max = np.max(differences, axis=-1)\n",
    "#             difference_mean[:, win_len-1] = diff_mean\n",
    "#             difference_max[:, win_len-1] = diff_max\n",
    "#             diff_envelope1[:, win_len-1] = diff_mean + diff_std\n",
    "#             diff_envelope2[:, win_len-1] = diff_mean + 2 * diff_std\n",
    "#             diff_envelope3[:, win_len-1] = diff_mean + 3 * diff_std\n",
    "\n",
    "#         # --- GEV per line ---\n",
    "#         elif method == 'gev':\n",
    "#             for i in range(num_lines):\n",
    "#                 shape_, loc_, scale_ = genextreme.fit(differences[i])\n",
    "#                 gev_mean[i, win_len-1] = loc_\n",
    "#                 gev_p95_stats[i, win_len-1] = genextreme.ppf(0.95, shape_, loc_, scale_)\n",
    "#                 gev_p99_stats[i, win_len-1] = genextreme.ppf(0.99, shape_, loc_, scale_)\n",
    "\n",
    "#         # --- Gaussian per line (analytic) ---\n",
    "#         elif method == 'gaussian':\n",
    "#             # mu, sigma = norm.fit(differences)\n",
    "#             # gaussian_mean[:, win_len - 1] = mu\n",
    "#             # gaussian_p95_stats[:, win_len - 1] = norm.ppf(0.95, mu, sigma)\n",
    "#             # gaussian_p99_stats[:, win_len - 1] = norm.ppf(0.99, mu, sigma)\n",
    "\n",
    "#             gaussian_mean[:, win_len - 1] = np.mean(differences, axis=-1)\n",
    "#             gaussian_p95_stats[:, win_len-1] = np.percentile(differences, 95, axis=-1)\n",
    "#             gaussian_p99_stats[:, win_len-1] = np.percentile(differences, 99, axis=-1)\n",
    "\n",
    "#         elif method == 'all':\n",
    "#             # --- STD stats ---\n",
    "#             std_mean[:, win_len - 1] = np.mean(stds, axis=-1)\n",
    "#             std_max[:, win_len - 1] = np.max(stds, axis=-1)\n",
    "#             std_std = np.std(stds, axis=-1)\n",
    "#             std_envelope1[:, win_len - 1] = std_mean[:, win_len - 1] + std_std\n",
    "#             std_envelope2[:, win_len - 1] = std_mean[:, win_len - 1] + 2 * std_std\n",
    "#             std_envelope3[:, win_len - 1] = std_mean[:, win_len - 1] + 3 * std_std\n",
    "\n",
    "#             # --- DIFF stats ---\n",
    "#             diff_mean = np.mean(differences, axis=-1)\n",
    "#             diff_std = np.std(differences, axis=-1)\n",
    "#             diff_max = np.max(differences, axis=-1)\n",
    "#             difference_mean[:, win_len - 1] = diff_mean\n",
    "#             difference_max[:, win_len - 1] = diff_max\n",
    "#             diff_envelope1[:, win_len - 1] = diff_mean + diff_std\n",
    "#             diff_envelope2[:, win_len - 1] = diff_mean + 2 * diff_std\n",
    "#             diff_envelope3[:, win_len - 1] = diff_mean + 3 * diff_std\n",
    "\n",
    "#             # --- GEV per line ---\n",
    "#             def fit_gev_per_line(line_diffs):\n",
    "#                 shape_, loc_, scale_ = genextreme.fit(line_diffs)\n",
    "#                 p95 = genextreme.ppf(0.95, shape_, loc_, scale_)\n",
    "#                 p99 = genextreme.ppf(0.99, shape_, loc_, scale_)\n",
    "#                 return loc_, p95, p99\n",
    "\n",
    "#             # Using multiprocess\n",
    "#             from multiprocess import Pool\n",
    "#             with Pool() as pool:\n",
    "#                 gev_results = pool.map(fit_gev_per_line, [row for row in differences])\n",
    "\n",
    "#             gev_results = np.array(gev_results)\n",
    "\n",
    "#             # Apply along axis 1 (each line independently)\n",
    "#             # gev_results = np.apply_along_axis(\n",
    "#             #     lambda arr: fit_gev_per_line(arr), axis=1, arr=differences\n",
    "#             # )\n",
    "#             # gev_results shape: (num_lines, 3)\n",
    "\n",
    "#             gev_mean[:, win_len - 1] = gev_results[:, 0]\n",
    "#             gev_p95_stats[:, win_len - 1] = gev_results[:, 1]\n",
    "#             gev_p99_stats[:, win_len - 1] = gev_results[:, 2]\n",
    "\n",
    "#             # for i in range(num_lines):\n",
    "#             #     shape_, loc_, scale_ = genextreme.fit(differences[i])\n",
    "#             #     gev_mean[i, win_len - 1] = loc_\n",
    "#             #     gev_p95_stats[i, win_len - 1] = genextreme.ppf(0.95, shape_, loc_, scale_)\n",
    "#             #     gev_p99_stats[i, win_len - 1] = genextreme.ppf(0.99, shape_, loc_, scale_)\n",
    "\n",
    "#             # --- Gaussian per line (analytic) ---\n",
    "#             gaussian_mean[:, win_len - 1] = np.mean(differences, axis=-1)\n",
    "#             gaussian_p95_stats[:, win_len-1] = np.percentile(differences, 95, axis=-1)\n",
    "#             gaussian_p99_stats[:, win_len-1] = np.percentile(differences, 99, axis=-1)\n",
    "\n",
    "#     # --- Mirror the ends for symmetry (like original code) ---\n",
    "#     if method == 'std':\n",
    "#         std_mean[:, -win_len:] = np.fliplr(std_mean[:, :win_len])\n",
    "#         std_max[:, -win_len:] = np.fliplr(std_max[:, :win_len])\n",
    "#         std_envelope1[:, -win_len:] = np.fliplr(std_envelope1[:, :win_len])\n",
    "#         std_envelope2[:, -win_len:] = np.fliplr(std_envelope2[:, :win_len])\n",
    "#         std_envelope3[:, -win_len:] = np.fliplr(std_envelope3[:, :win_len])\n",
    "#         return std_mean, std_max, std_envelope1, std_envelope2, std_envelope3\n",
    "\n",
    "#     elif method == 'diff':\n",
    "#         difference_mean[:, -win_len:] = np.fliplr(difference_mean[:, :win_len])\n",
    "#         difference_max[:, -win_len:] = np.fliplr(difference_max[:, :win_len])\n",
    "#         diff_envelope1[:, -win_len:] = np.fliplr(diff_envelope1[:, :win_len])\n",
    "#         diff_envelope2[:, -win_len:] = np.fliplr(diff_envelope2[:, :win_len])\n",
    "#         diff_envelope3[:, -win_len:] = np.fliplr(diff_envelope3[:, :win_len])\n",
    "#         return difference_mean, difference_max, diff_envelope1, diff_envelope2, diff_envelope3\n",
    "\n",
    "#     elif method == 'gev':\n",
    "#         gev_mean[:, -win_len:] = np.fliplr(gev_mean[:, :win_len])\n",
    "#         gev_p95_stats[:, -win_len:] = np.fliplr(gev_p95_stats[:, :win_len])\n",
    "#         gev_p99_stats[:, -win_len:] = np.fliplr(gev_p99_stats[:, :win_len])\n",
    "#         return gev_mean, gev_p95_stats, gev_p99_stats\n",
    "\n",
    "#     elif method == 'gaussian':\n",
    "#         gaussian_mean[:, -win_len:] = np.fliplr(gaussian_mean[:, :win_len])\n",
    "#         gaussian_p95_stats[:, -win_len:] = np.fliplr(gaussian_p95_stats[:, :win_len])\n",
    "#         gaussian_p99_stats[:, -win_len:] = np.fliplr(gaussian_p99_stats[:, :win_len])\n",
    "#         return gaussian_mean, gaussian_p95_stats, gaussian_p99_stats\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid method specified.\")\n",
    "\n",
    "# # def uncertainty_comparison(residuals, uncertainties, plot=False):\n",
    "# #     nonzero_idx = np.nonzero(\n",
    "# #         (residuals != 0) & (~np.isnan(residuals)) & (uncertainties != 0)\n",
    "# #     )\n",
    "# #     uncertainty_ratio = np.full(residuals.shape, np.nan)\n",
    "# #     uncertainty_ratio[nonzero_idx] = uncertainties[nonzero_idx] / np.abs(\n",
    "# #         residuals[nonzero_idx]\n",
    "# #     )\n",
    "# #     fail_points = np.nonzero(uncertainty_ratio < 1)\n",
    "# #     ur_flat = uncertainty_ratio[nonzero_idx].flatten()\n",
    "# #     total_count = len(ur_flat)\n",
    "# #     fail_count = len(fail_points[0])\n",
    "# #     pass_percentage = 100 - fail_count / total_count * 100\n",
    "# #     current_rmse = np.sqrt(\n",
    "# #         np.mean((residuals[nonzero_idx] - uncertainties[nonzero_idx]) ** 2)\n",
    "# #     )\n",
    "# #     mean_error = np.mean(uncertainties[nonzero_idx]\n",
    "# #                          - np.abs(residuals[nonzero_idx]))\n",
    "# #     std_dev = np.std(uncertainties[nonzero_idx] - np.abs(residuals[nonzero_idx]))\n",
    "# #\n",
    "# #\n",
    "# #     coverage = np.sum(np.abs(residuals[nonzero_idx] <= uncertainties[nonzero_idx]))/total_count\n",
    "# #\n",
    "# #     if plot:\n",
    "# #         # plt.figure()\n",
    "# #         # plt.hist(ur_flat, bins=100, log=True)\n",
    "# #         # plt.xlim(0, 5)\n",
    "# #         # plt.xlabel(\"Uncertainty Ratio\")\n",
    "# #         # plt.ylabel(\"Count\")\n",
    "# #         # plt.grid()\n",
    "# #         # plt.show()\n",
    "# #         max_uncertainty = np.max(uncertainties[nonzero_idx])\n",
    "# #         plt.figure()\n",
    "# #         plt.plot(np.abs(residuals.T), uncertainties.T, \".\")\n",
    "# #         plt.plot([0, max_uncertainty], [0, max_uncertainty], \"r\")\n",
    "# #         plt.grid()\n",
    "# #         plt.xlabel(\"Residual\")\n",
    "# #         plt.ylabel(\"Uncertainty Estimate\")\n",
    "# #         plt.title(f\"\"\"\n",
    "# #             Total Point Count: {total_count}, Failed Point Count: {fail_count}\n",
    "# #             Pass Percentage: {pass_percentage:.2f}%, coverage: {coverage:.2f}%,\n",
    "# #             RMSE: {current_rmse:.02f}, Mean Difference: {mean_error:.02f}\n",
    "# #             \"\"\")\n",
    "# #         plt.show()\n",
    "# #\n",
    "# #     return {\n",
    "# #         \"fail_cts\": fail_count,\n",
    "# #         \"total_cts\": total_count,\n",
    "# #         \"percentage\": pass_percentage,\n",
    "# #         \"coverage\": coverage,\n",
    "# #         \"mean\": mean_error,\n",
    "# #         \"rmse\": current_rmse,\n",
    "# #         \"fail_pts\": fail_points,\n",
    "# #         \"std_dev\": std_dev}\n",
    "\n",
    "# def uncertainty_comparison(residuals, uncertainties):\n",
    "#     nonzero_idx = np.nonzero(\n",
    "#         (residuals != 0) & (~np.isnan(residuals)) & (uncertainties != 0)\n",
    "#     )\n",
    "#     uncertainty_ratio = np.full(residuals.shape, np.nan)\n",
    "#     uncertainty_ratio[nonzero_idx] = uncertainties[nonzero_idx] / np.abs(residuals[nonzero_idx])\n",
    "#     fail_points = np.nonzero(uncertainty_ratio < 1)\n",
    "#     ur_flat = uncertainty_ratio[nonzero_idx].flatten()\n",
    "#     total_count = len(ur_flat)\n",
    "#     fail_count = len(fail_points[0])\n",
    "#     pass_percentage = 100 - fail_count / total_count * 100\n",
    "#     current_rmse = np.sqrt(np.mean((residuals[nonzero_idx] - uncertainties[nonzero_idx]) ** 2))\n",
    "#     mean_error = np.mean(uncertainties[nonzero_idx] - np.abs(residuals[nonzero_idx]))\n",
    "#     std_dev = np.std(uncertainties[nonzero_idx] - np.abs(residuals[nonzero_idx]))\n",
    "#     sharp = np.mean(uncertainties[nonzero_idx])\n",
    "#     corr = np.corrcoef(uncertainties[nonzero_idx], np.abs(residuals[nonzero_idx]))[0, 1] if len(np.abs(residuals[nonzero_idx])) > 1 else np.nan\n",
    "\n",
    "#     return {\n",
    "#         \"total_cts\": total_count,\n",
    "#         \"fail_cts\": fail_count,\n",
    "#         \"percentage\": pass_percentage,\n",
    "#         \"rmse\": current_rmse,\n",
    "#         \"mean\": mean_error,\n",
    "#         \"std_dev\": std_dev,\n",
    "#         \"sharp\": sharp,\n",
    "#         \"corr\": corr}, uncertainties[nonzero_idx], np.abs(residuals[nonzero_idx])\n",
    "\n",
    "# def multi_uncertainty_comparison(\n",
    "#     residuals,\n",
    "#     uncertainties_dict,\n",
    "#     resolution,\n",
    "#     desired_linespacing_meters=None,\n",
    "#     fn=None,\n",
    "#     plot_grid=(3, 3),\n",
    "#     path=None,\n",
    "#     plot_boxplots=True\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Compare multiple uncertainty surfaces against residuals in one figure.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     residuals : np.ndarray\n",
    "#         2D array of residual surface.\n",
    "#     uncertainties_dict : dict\n",
    "#         Dictionary of uncertainty name -> uncertainty array.\n",
    "#     resolution : float\n",
    "#         Grid resolution in meters.\n",
    "#     desired_linespacing_meters : float, optional\n",
    "#         Used for labeling titles.\n",
    "#     fn : str, optional\n",
    "#         Surface name for the first title.\n",
    "#     plot_grid : tuple\n",
    "#         (nrows, ncols) for subplot grid.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def uncertainty_comparison(residuals, uncertainties):\n",
    "#         nonzero_idx = np.nonzero(\n",
    "#             (residuals != 0) & (~np.isnan(residuals)) & (uncertainties != 0)\n",
    "#         )\n",
    "#         uncertainty_ratio = np.full(residuals.shape, np.nan)\n",
    "#         uncertainty_ratio[nonzero_idx] = uncertainties[nonzero_idx] / np.abs(residuals[nonzero_idx])\n",
    "#         fail_points = np.nonzero(uncertainty_ratio < 1)\n",
    "#         ur_flat = uncertainty_ratio[nonzero_idx].flatten()\n",
    "#         total_count = len(ur_flat)\n",
    "#         fail_count = len(fail_points[0])\n",
    "#         pass_percentage = 100 - fail_count / total_count * 100\n",
    "#         current_rmse = np.sqrt(np.mean((residuals[nonzero_idx] - uncertainties[nonzero_idx]) ** 2))\n",
    "#         mean_error = np.mean(uncertainties[nonzero_idx] - np.abs(residuals[nonzero_idx]))\n",
    "#         std_dev = np.std(uncertainties[nonzero_idx] - np.abs(residuals[nonzero_idx]))\n",
    "#         sharp = np.mean(uncertainties[nonzero_idx])\n",
    "#         corr = np.corrcoef(uncertainties[nonzero_idx], np.abs(residuals[nonzero_idx]))[0, 1] if len(np.abs(residuals[nonzero_idx])) > 1 else np.nan\n",
    "\n",
    "#         return pass_percentage, current_rmse, mean_error, std_dev, sharp, corr\n",
    "\n",
    "#     # ---- Create figure ----\n",
    "#     nrows, ncols = plot_grid\n",
    "#     fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 12), layout=\"constrained\")\n",
    "\n",
    "#     axes = axes.flatten()\n",
    "#     names = list(uncertainties_dict.keys())\n",
    "#     results = []\n",
    "\n",
    "#     for i, (name, uncertainty) in enumerate(uncertainties_dict.items()):\n",
    "#         ax = axes[i]\n",
    "\n",
    "#         # Compute stats\n",
    "#         pass_percentage, rmse, mean_error, std_dev, sharp, corr = uncertainty_comparison(residuals, uncertainty)\n",
    "\n",
    "#         # Append stats for CSV\n",
    "#         results.append({\n",
    "#             \"Seabed\": fn,\n",
    "#             \"Uncertainty Method\": name,\n",
    "#             \"Line spacing \": desired_linespacing_meters,\n",
    "#             \"Pass %\": pass_percentage,\n",
    "#             \"RMSE\": rmse,\n",
    "#             \"Bias (Mean Error)\": mean_error,\n",
    "#             \"Std Dev\": std_dev,\n",
    "#             \"Sharpness\": sharp,\n",
    "#             \"Correlation\": corr\n",
    "#         })\n",
    "\n",
    "#         # Scatter comparison plot\n",
    "#         nonzero_idx = np.nonzero(\n",
    "#             (residuals != 0) & (~np.isnan(residuals)) & (uncertainty != 0)\n",
    "#         )\n",
    "#         max_unc = np.max(uncertainty[nonzero_idx])\n",
    "#         ax.plot(np.abs(residuals[nonzero_idx]), uncertainty[nonzero_idx], \".\", alpha=0.3)\n",
    "#         ax.plot([0, max_unc], [0, max_unc], \"r\", lw=1)\n",
    "\n",
    "#         ax.set_xlabel(\"Abs. Residual (m)\")\n",
    "#         ax.set_ylabel(\"Uncertainty (m)\")\n",
    "#         ax.set_xlim(0, max_unc)\n",
    "#         ax.set_ylim(0, max_unc)\n",
    "#         ax.grid(True, alpha=0.3)\n",
    "\n",
    "#         # Title with stats\n",
    "#         ax.set_title(\n",
    "#             f\"{name}\\nPass: {pass_percentage:.1f}%  RMSE: {rmse:.2f}  Bias: {mean_error:.2f}\\n  \"\n",
    "#             f\"Corr: {corr:.2f}, Sharp: {sharp:.2f}\",  fontsize=12,\n",
    "#         )\n",
    "\n",
    "#     # Remove unused axes\n",
    "#     for j in range(i + 1, len(axes)):\n",
    "#         fig.delaxes(axes[j])\n",
    "\n",
    "#     if fn and desired_linespacing_meters:\n",
    "#         fig.suptitle(\n",
    "#             f\"Uncertainty Comparisons for {fn} ({resolution}m grid, {desired_linespacing_meters}m spacing)\",\n",
    "#             fontsize=14,\n",
    "#         )\n",
    "#     else:\n",
    "#         fig.suptitle(\"Uncertainty Comparisons\", fontsize=14)\n",
    "#     outpath = f'{path}_uncertainty_comparisons.png'\n",
    "#     plt.savefig(outpath, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     # ---- Export to CSV ----\n",
    "#     if path:\n",
    "#         df = pd.DataFrame(results)\n",
    "#         outpath = f'{path}_stats.csv'\n",
    "#         df.to_csv(f'{outpath}', index=False)\n",
    "#         print(f\"Statistics exported to {outpath}\")\n",
    "\n",
    "#     # ---- Optional: Combined Boxplot of Residuals vs Uncertainties ----\n",
    "\n",
    "#     if plot_boxplots:\n",
    "#         # Collect data\n",
    "#         data = []\n",
    "#         labels = []\n",
    "\n",
    "#         # Residuals (absolute values)\n",
    "#         res_vals = np.abs(residuals[(residuals != 0) & (~np.isnan(residuals))]).flatten()\n",
    "#         data.append(res_vals)\n",
    "#         labels.append(\"Abs.  Residuals\")\n",
    "\n",
    "#         # Each uncertainty\n",
    "#         for name, uncertainty in uncertainties_dict.items():\n",
    "#             unc_vals = uncertainty[(uncertainty != 0) & (~np.isnan(uncertainty))].flatten()\n",
    "#             data.append(unc_vals)\n",
    "#             labels.append(name)\n",
    "\n",
    "#         # Combined boxplot\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.boxplot(data, patch_artist=True, labels=labels,\n",
    "#                     boxprops=dict(facecolor='lightgray', alpha=0.7),\n",
    "#                     medianprops=dict(color='red', linewidth=1.5))\n",
    "#         plt.title(f\"Uncertainty Boxplots for {fn} ({resolution}m grid, {desired_linespacing_meters}m spacing)\")\n",
    "#         plt.ylabel(\"Uncertainty (m)\")\n",
    "#         plt.grid(alpha=0.3)\n",
    "#         plt.xticks(rotation=30)\n",
    "#         outpath = f'{path}_uncertainty_boxplots.png'\n",
    "#         plt.savefig(outpath, bbox_inches='tight')\n",
    "#         plt.show()\n",
    "\n",
    "#     # return results\n",
    "\n",
    "\n",
    "# def single_run(settings: tuple, max_multiple=4, tiled: bool = False) -> dict:\n",
    "#     filename = settings[0]\n",
    "#     linespacing = settings[1]\n",
    "#     multiple = settings[2]\n",
    "#     fxn = settings[3][0]\n",
    "#     fxn_method = settings[3][1]\n",
    "#     fxn_name = settings[3][2]\n",
    "#     if_fft_method = settings[3][3]\n",
    "#     # if_tiled:bool = False\n",
    "\n",
    "#     # Extract data from Bathymetry file\n",
    "#     # bathy_dict = data_utils.load_file(filename=filename,\n",
    "#     #                        folder='../../seafloor_files',\n",
    "#     #                        verbose=False)\n",
    "\n",
    "#     bathy_dict = data_utils.load_file(filename=filename,\n",
    "#                                       folder=r'C:\\Users\\eadediran\\PycharmProjects\\interpolation_uncertainty_francis_pro\\tests',\n",
    "#                                       verbose=False)\n",
    "\n",
    "#     depth = data_utils.remove_edge_Nans(depth=bathy_dict['depth'], ndv=bathy_dict['ndv'])\n",
    "#     resolution = bathy_dict['resolution']\n",
    "\n",
    "#     column_indices = matrix_utils.get_column_indices(array_len=depth.shape[1],\n",
    "#                                         resolution=resolution,\n",
    "#                                         linespacing_meters=linespacing,\n",
    "#                                         max_multiple=max_multiple)\n",
    "\n",
    "#     # # Compute Residuals and Uncertainties#\n",
    "#     residual_segment_data = matrix_utils.matrix2strip(depth,\n",
    "#                                          column_indices=column_indices,\n",
    "#                                          multiple=multiple)\n",
    "#     residual_data, _ = compute_residual(residual_segment_data)\n",
    "\n",
    "#     uncertainty_segment_data = matrix_utils.matrix2strip(depth,\n",
    "#                                             column_indices=column_indices,\n",
    "#                                             multiple=multiple)\n",
    "#     uncertainty_data, _ = compute_residual(uncertainty_segment_data)\n",
    "\n",
    "#     # Different inputs for FFT and Spatial functions\n",
    "#     if if_fft_method:\n",
    "#         strip = fxn(data=uncertainty_data,\n",
    "#                     resolution=resolution,\n",
    "#                     multiple=multiple, method=fxn_method)\n",
    "#     else:\n",
    "#         pixel_width = uncertainty_data.shape[1]\n",
    "#         if fxn_name == 'diff_max':\n",
    "#             strip = fxn(data=uncertainty_data,\n",
    "#                         # interpolation_cell_distance=pixel_width,\n",
    "#                         multiple=multiple, method=fxn_method)[1]\n",
    "#         elif fxn_name == 'diff_envelope1': # 'diff_envelope1', 'diff_envelope3', 'gaussian_95', 'gaussian_99'\n",
    "#             strip = fxn(data=uncertainty_data,\n",
    "#                         # interpolation_cell_distance=pixel_width,\n",
    "#                         multiple=multiple, method=fxn_method)[2]\n",
    "#         elif fxn_name == 'diff_envelope3':\n",
    "#             strip = fxn(data=uncertainty_data,\n",
    "#                         # interpolation_cell_distance=pixel_width,\n",
    "#                         multiple=multiple, method=fxn_method)[4]\n",
    "#         elif fxn_name == 'gaussian_95':\n",
    "#             strip = fxn(data=uncertainty_data,\n",
    "#                         # interpolation_cell_distance=pixel_width,\n",
    "#                         multiple=multiple, method=fxn_method)[1]\n",
    "#         elif fxn_name == 'gaussian_99':\n",
    "#             strip = fxn(data=uncertainty_data,\n",
    "#                         # interpolation_cell_distance=pixel_width,\n",
    "#                         multiple=multiple, method=fxn_method)[2]\n",
    "#         elif fxn_name == 'gaussian_mean':\n",
    "#             strip = fxn(data=uncertainty_data,\n",
    "#                         # interpolation_cell_distance=pixel_width,\n",
    "#                         multiple=multiple, method=fxn_method)[0]\n",
    "\n",
    "#     if strip.shape != residual_data.shape:\n",
    "#         # print(f\"strip shape: {strip.shape}, residual shape: {residual_data.shape}\")\n",
    "#         # print(f\"filename: {filename}, linespacing: {linespacing}, multiple: {multiple}, method: {fxn_name}\")\n",
    "#         raise ValueError(\n",
    "#             f\"Uncertainty strip shape {strip.shape} does not match residual data shape {residual_data.shape}\",\n",
    "#             f\"filename: {filename}, linespacing: {linespacing}, multiple: {multiple}, method: {fxn_name}\")\n",
    "\n",
    "#     # Reconstruct Matrix from Strip\n",
    "#     residuals = matrix_utils.strip2matrix(data_strip=residual_data,\n",
    "#                              original_shape=depth.shape,\n",
    "#                              column_indices=column_indices)\n",
    "\n",
    "#     output_uncertainty = matrix_utils.strip2matrix(data_strip=strip,\n",
    "#                                       original_shape=depth.shape,\n",
    "#                                       column_indices=column_indices)\n",
    "\n",
    "#     if tiled:\n",
    "#         output_uncertainty = transform_matrix(output_uncertainty, column_indices)\n",
    "\n",
    "#     # uncertainty_error = output_uncertainty - np.abs(residuals)\n",
    "#     # uncertainty_error = uncertainty_error[~np.isnan(uncertainty_error)]\n",
    "#     stats, uncertainty_cleaned, residuals_cleaned, = uncertainty_comparison(residuals=residuals,\n",
    "#                                               uncertainties=output_uncertainty)\n",
    "\n",
    "#     results = {\"filename\": filename,\n",
    "#                \"linespacing\": linespacing,\n",
    "#                \"multiple\": multiple,\n",
    "#                \"method\": fxn_name,\n",
    "#                \"residuals\": residuals_cleaned,\n",
    "#                \"uncertainty\": uncertainty_cleaned,\n",
    "#                \"stats\": stats}\n",
    "\n",
    "#     # df = pd.DataFrame.from_dict(results)\n",
    "\n",
    "#     return results\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# def export_uncertainty_results(results, csv_path=\"uncertainty_comparison_results.csv\", sort_by=\"method\"):\n",
    "#     \"\"\"\n",
    "#     Convert a list of uncertainty comparison results into a sorted and flattened CSV table.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     results : list of dict\n",
    "#         List containing entries with 'filename', 'linespacing', 'method', and nested 'stats'.\n",
    "#     csv_path : str, optional\n",
    "#         Path to save the CSV file (default is 'uncertainty_comparison_results.csv').\n",
    "#     sort_by : str, optional\n",
    "#         Field to sort by, e.g., 'method', 'percentage', or 'rmse'. Default is 'method'.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         The flattened and sorted DataFrame of results.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Optional renaming for nicer output\n",
    "#     method_map = {\n",
    "#         \"amplitude\": \"ASD\",\n",
    "#         \"psd_n\": \"PSD (n)\",\n",
    "#         \"psd_lf\": \"PSD (lf)\",\n",
    "#         \"psd_df\": \"PSD (df)\",\n",
    "#         \"diff_max\": \"Spatial Max Diff\",\n",
    "#         \"diff_envelope1\": \"Spatial Diff Envelope1\",\n",
    "#         \"diff_envelope3\": \"Spatial Diff Envelope3\",\n",
    "#         \"gaussian_95\": \"Gaussian (95%)\",\n",
    "#         \"gaussian_99\": \"Gaussian (99%)\"\n",
    "#     }\n",
    "\n",
    "#     # Flatten the results\n",
    "#     flat_results = []\n",
    "#     for r in results:\n",
    "#         stats = r[\"stats\"]\n",
    "#         flat_results.append({\n",
    "#             \"Seabed\": r[\"filename\"].replace(\".tif\", \"\"),\n",
    "#             \"Method\": method_map.get(r[\"method\"], r[\"method\"]),\n",
    "#             \"Spacing\": r[\"linespacing\"],\n",
    "#             \"Pass\": float(stats[\"percentage\"]),\n",
    "#             \"RMSE\": float(stats[\"rmse\"]),\n",
    "#             \"Bias\": float(stats[\"mean\"]),\n",
    "#             \"Std\": float(stats[\"std_dev\"]),\n",
    "#             \"Sharpness\": float(stats[\"sharp\"]),\n",
    "#             \"Correlation\": float(stats[\"corr\"]),\n",
    "#             \"Uncertainty\": r[\"uncertainty\"],\n",
    "#             \"Residuals\": r[\"residuals\"],\n",
    "#         })\n",
    "\n",
    "#     # Convert to DataFrame\n",
    "#     df = pd.DataFrame(flat_results)\n",
    "\n",
    "#     # Sort the DataFrame\n",
    "#     if sort_by in df.columns:\n",
    "#         df = df.sort_values(by=sort_by, ascending=True)\n",
    "#     elif sort_by == \"method\":\n",
    "#         df = df.sort_values(by=\"Method\", ascending=True)\n",
    "\n",
    "#     # Export to CSV\n",
    "#     df.to_csv(csv_path, index=False)\n",
    "#     print(f\"Results exported to: {csv_path}\")\n",
    "\n",
    "#     return df, csv_path\n",
    "\n",
    "\n",
    "# def transform_matrix(matrix_data, row_indices):\n",
    "#     matrix_data_rows = matrix_data[row_indices[:-1], :]\n",
    "#     n_times = int(row_indices[1] - row_indices[0])\n",
    "#     matrix_data_tiles = np.repeat(matrix_data_rows, n_times, axis=0)\n",
    "#     matrix_data[:row_indices[0], :] = np.nan\n",
    "#     matrix_data[row_indices[-1]:, :] = np.nan\n",
    "#     matrix_data[row_indices[0]:row_indices[-1], :] = matrix_data_tiles\n",
    "#     return matrix_data"
   ]
=======
   "source": []
>>>>>>> cd752014934dfa9d27edc3d2f80b804e80ccee2e
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NBS_Uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
